{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import xgboost as xgb\n",
    "import scipy\n",
    "from geopy import distance\n",
    "import geopy\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "plt.rcParams['figure.figsize'] = [16, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TRAIN_DATASET = './data/train.csv'\n",
    "PATH_TEST_DATASET = './data/test.csv'\n",
    "PATH_SAMPLE_SUMBISSION = './data/sample_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(PATH_TEST_DATASET, infer_datetime_format=True, parse_dates=['pickup_datetime'],  index_col='id')\n",
    "df_train = pd.read_csv(PATH_TRAIN_DATASET, infer_datetime_format=True,parse_dates=['pickup_datetime'], index_col='id')\n",
    "df_sample_submission = pd.read_csv(PATH_SAMPLE_SUMBISSION)\n",
    "df_original_train = df_train.copy()\n",
    "df_original_test = df_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A brief description of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned in the challenge's page, the provided training dataset contains the following fields, as can be verified bellow:\n",
    "\n",
    "- `id` - a unique identifier for each trip\n",
    "- `vendor_id` - a code indicating the provider associated with the trip record\n",
    "- `pickup_datetime` - date and time when the meter was engaged\n",
    "- `dropoff_datetime` - date and time when the meter was disengaged\n",
    "- `passenger_count` - the number of passengers in the vehicle (driver entered value)\n",
    "- `pickup_longitude` - the longitude where the meter was engaged\n",
    "- `pickup_latitude` - the latitude where the meter was engaged\n",
    "- `dropoff_longitude` - the longitude where the meter was disengaged\n",
    "- `dropoff_latitude` - the latitude where the meter was disengaged\n",
    "- `store_and_fwd_flag` - This flag indicates whether the trip record was held in vehicle memory before sending to the vendor because the vehicle did not have a connection to the server -`Y`=store and forward; `N`=not a store and forward trip\n",
    "- `trip_duration` - duration of the trip in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No Null Columns\n",
    "\n",
    "It's important to notice that the provided database has been already preprocessed and cleaned, so no null values can be found in the base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the whole Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the data for analysis\n",
    "\n",
    "Before the analysis, a few steps must be done to prepare the data. Also, the dropoff_datetime column will be dropped because it's redundant since we have the trip_duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['pickup_datetime'] = df_train['pickup_datetime'].dt.to_pydatetime()\n",
    "df_test['pickup_datetime'] = df_test['pickup_datetime'].dt.to_pydatetime()\n",
    "df_train.drop('dropoff_datetime', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trip Duration\n",
    "\n",
    "Since trip duration is the target variable, it will be the first to be checked. After aplying the describe function, a few strange values appear, like the min and max values, 1s and 3526282s (almost 980h) respectively. Trips with a such a low or high values for duration can decrease the accuracy of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['trip_duration'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get rid of the outliers, lets apply the the [Interquartile Range](https://en.wikipedia.org/wiki/Interquartile_range) technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df_train['trip_duration'].quantile(0.25)\n",
    "Q3 = df_train['trip_duration'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "df_train = df_train[~((df_train['trip_duration'] < (Q1 - 1.5 * IQR)) |(df_train['trip_duration'] > (Q3 + 1.5 * IQR)))]\n",
    "df_train['trip_duration'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even applying the IQR technique, the minimum value for a trip duration keeps very low, so values bellow 90 seconds will also be disconsidered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train['trip_duration'] > 1]\n",
    "df_train = df_train[df_train['trip_duration'] < 7200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_train['trip_duration'], axlabel='Trip Duration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzing the Lat-Long Columns\n",
    "\n",
    "To understand the distribution we must plot the values for each of the Latitude and Longitude provided. From the graph is possible to see that there are some datapoints from trips starting and finishing outside NYC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_lat_long(df_data):\n",
    "    fig, ax = plt.subplots(2,2,figsize=(16, 10), sharex=False, sharey = False)\n",
    "    sns.distplot(df_data['pickup_latitude'], axlabel = 'Pickup Latitude',ax=ax[0,0])\n",
    "    sns.distplot(df_data['pickup_longitude'], axlabel = 'Pickup_Longitude', ax=ax[0,1])\n",
    "    sns.distplot(df_data['dropoff_latitude'], axlabel = 'Dropoff Latitude', ax=ax[1, 0])\n",
    "    sns.distplot(df_data['dropoff_longitude'], axlabel = 'Dropoff Longitude', ax=ax[1, 1])\n",
    "    plt.show()\n",
    "plot_lat_long(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Values Starting or Finishing out of New York City\n",
    "\n",
    "Select values only within the NYC bounding Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYC_BOUNDING_BOX = [(40.4774,-74.2589), ( 40.9176, -73.7004)]\n",
    "\n",
    "filter_lat_long = df_train['pickup_latitude'] < NYC_BOUNDING_BOX[1][0]\n",
    "filter_lat_long &= df_train['pickup_latitude'] > NYC_BOUNDING_BOX[0][0]\n",
    "filter_lat_long &= df_train['pickup_longitude'] < NYC_BOUNDING_BOX[1][1]\n",
    "filter_lat_long &= df_train['pickup_longitude'] > NYC_BOUNDING_BOX[0][1]\n",
    "\n",
    "filter_lat_long &= df_train['dropoff_latitude'] < NYC_BOUNDING_BOX[1][0]\n",
    "filter_lat_long &= df_train['dropoff_latitude'] > NYC_BOUNDING_BOX[0][0]\n",
    "filter_lat_long &= df_train['dropoff_longitude'] < NYC_BOUNDING_BOX[1][1]\n",
    "filter_lat_long &= df_train['dropoff_longitude'] > NYC_BOUNDING_BOX[0][1]\n",
    "\n",
    "df_train = df_train[filter_lat_long]\n",
    "\n",
    "plot_lat_long(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting New Features: DIstance and Average Speed\n",
    "\n",
    "Two more features will be added using the fields provided. Since we have the coorinates from the pickup and dropoff points, we can calculate the distance between points. The distance function chosen for that is the Manhattan Distance, City Block distance or [Taxicab geometry](https://en.wikipedia.org/wiki/Taxicab_geometry). The final distance is given in Kilometers\n",
    "\n",
    "The other feature is the average speed for the whole route, for that we will use the distance obtained in the previous step and the trip duration. The average speed will be in Kilometer per hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYC_LAT_KILOMETER_PER_DEGREE = geopy.distance.distance((40.7831, -73.9712),(41.7831, -73.9712)).kilometers\n",
    "NYC_LON_KILOMETER_PER_DEGREE = geopy.distance.distance((40.7831, -73.9712),(40.7831, -72.9712)).kilometers\n",
    "\n",
    "NYC_DEGREE_KM = 111.05938787411571\n",
    "\n",
    "def calculate_city_block_distance(df_data):\n",
    "    delta_lat = np.absolute(df_data.pickup_latitude - df_data.dropoff_latitude) * NYC_LAT_KILOMETER_PER_DEGREE    \n",
    "    delta_lon = np.absolute(df_data.pickup_longitude - df_data.dropoff_longitude) * NYC_LON_KILOMETER_PER_DEGREE    \n",
    "    return delta_lat + delta_lon\n",
    "\n",
    "\n",
    "df_train['distance'] = calculate_city_block_distance(df_train)\n",
    "df_train['avg_speed'] = df_train['distance']/(df_train['trip_duration']/3600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Distance and Average Speed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(16, 10), sharex=False, sharey = False)\n",
    "sns.distplot(df_train['distance'], axlabel = 'Distance',ax=ax[0])\n",
    "sns.distplot(df_train['avg_speed'], axlabel = 'Average Speed',ax=ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even filtering small values for trip duration, we still can find some values that must be removed, since it don't reflects the reality, as can be seen in the graph above, where average speeds of 800 Km/h can be seen. To remove more sporious rows, we'll remove the any value with average speeds greater than 120 Km/h.\n",
    "Also distances close to 0 can be found and must be removed, for that we'll remove any values smaller than 0.250km\n",
    "\n",
    "Even filtering the values, is possible to see that the distance distribution is skewed, for this case, we will later apply a logarithmic transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train['avg_speed'] < 100]\n",
    "df_train = df_train[df_train['avg_speed'] > 1]\n",
    "df_train = df_train[df_train['distance'] > .25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzing Pickup Date\n",
    "\n",
    "As discussed before, only the pickup date will be used. A few features were created from the pickup datetime, they are justified by the typical behavior that we expect to see in the data, like \"Rush Hours\" or less traffic at weekends and Holidays. \n",
    "\n",
    "To analyze that behavior the following features were created: weekdays, holidays and pickup hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['pickup_date'] = df_train['pickup_datetime'].dt.date\n",
    "df_train['pickup_hour'] = df_train['pickup_datetime'].dt.hour\n",
    "df_train['pickup_weekday'] = df_train['pickup_datetime'].dt.day_name()\n",
    "\n",
    "holidays = [day.date() for day in calendar().holidays(start=df_train['pickup_date'].min(), end=df_train['pickup_date'].max())]\n",
    "df_train['holiday'] = df_train['pickup_date'].isin(holidays)\n",
    "df_train.drop('pickup_date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pickup Hour\n",
    "\n",
    "In most of cities is expected a well defined behavior regarding populational flow within the city, this way makes a sense to analyze the average trip duration per hour of the day, as can be seen in the graph bellow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_trip_duration_per_pickup_hour = df_train.groupby('pickup_hour')['trip_duration'].mean()\n",
    "avg_trip_duration_per_pickup_hour.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weekday vs Pickup Hour \n",
    "\n",
    "As shown in the graph bellow, different day of the week present a similar behavior, similar to the previous analysis, however the duration of each trip is different for each day of the week and in weekends the curves seen to be slightly shiffted by almost 2 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_trip_duration_per_weekday = df_train.groupby(['pickup_weekday', 'pickup_hour'])['trip_duration'].mean()\n",
    "avg_trip_duration_per_weekday.unstack(level=0).plot(subplots=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Holidays\n",
    "\n",
    "Applying the same analysis for holidays we have the graph bellow, which shows the average trip duration for a normal day and for a holiday. A similar behavior can be seen for both, however the curve for holiday is slightly shifted by a little more than 2 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_trip_duration_holiday = df_train.groupby(['holiday','pickup_hour'])['trip_duration'].mean()\n",
    "avg_trip_duration_holiday.unstack(level=0).plot(subplots=False)\n",
    "df_train.groupby(['holiday'])['trip_duration'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store and Forward\n",
    "\n",
    "The store and forward at first look may not give any information about the trip duration, but looking the graph bellow, it becomes clear there is a difference between the two. That difference may be explained by the technologies available to drivers like navigation apps, Internet or more modern cars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_trip_duration_per_store_flag = df_train.groupby(['store_and_fwd_flag','pickup_hour'])['trip_duration'].mean()\n",
    "avg_trip_duration_per_store_flag.unstack(level=0).plot(subplots=False)\n",
    "df_train.groupby(['store_and_fwd_flag'])['trip_duration'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vendor ID\n",
    "\n",
    "A naive analysis could lead to a misconception regarding the Vendor ID as a not usefull information, but given that technology has changed the private transportation market, a good routing or driver selection algorithm or papyment method can make a great difference in the trip_duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_trip_duration_per_store_flag = df_train.groupby(['vendor_id','pickup_hour'])['trip_duration'].mean()\n",
    "avg_trip_duration_per_store_flag.unstack(level=0).plot(subplots=False)\n",
    "df_train.groupby(['vendor_id'])['trip_duration'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Passangers\n",
    "\n",
    "In the same way as the previous analysis, it's worth to check the behavior of the number of passagengers transported and if it might give more infomation about the trip duration.\n",
    "\n",
    "As can be seen bellow, the graph of number of passangers shows a similar behavior for each number of passangers, but with different values for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['passenger_count'].value_counts()\n",
    "df_train = df_train[df_train['passenger_count']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# avg_trip_duration_per_passenger_count = df_train.groupby(['passenger_count'])['trip_duration'].mean()\n",
    "# avg_trip_duration_per_passenger_count.plot()\n",
    "avg_trip_duration_per_passenger_count = df_train[df_train['passenger_count']>0].groupby(['passenger_count','pickup_hour'])['trip_duration'].mean()\n",
    "avg_trip_duration_per_passenger_count.unstack(level=0).plot(subplots=False)\n",
    "df_train.groupby(['passenger_count'])['trip_duration'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data to build the models\n",
    "\n",
    "After analyzing all the field, create more features and understanding a little more about its distribution, we have to process some of the field to prepare the data, making it more suitable to the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot enconding\n",
    "\n",
    "To be properly used in supervised learning models the categorical fields independent of its type, must be transformed, since wrong information can be added to the model. One classical example of that are numerical categories where there is a logic relation between the numbers (greater than, sequences, , ratios, etc.) that might not exist in the category itself.\n",
    "\n",
    "To make the information more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.get_dummies(df_train, columns=['vendor_id', 'passenger_count', \n",
    "                                    'store_and_fwd_flag', 'pickup_weekday', 'pickup_hour', 'holiday'])\n",
    "df_train.drop(['pickup_datetime', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude'], axis=1, inplace=True)\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, as could be seen in the analysis above, some field present a very skewed distribution and apply a logarithmic transformation gives a better representation of the data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['trip_duration'] = np.log(df_train['trip_duration'] + 1)\n",
    "df_train['distance'] = np.log(df_train['distance'] + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score Function\n",
    "\n",
    "In the Kaggle competition there is no access to the true value of the trip duration for the test dataset and even though the score function is provided there is no way to calculate it. The only way to have the true score is subtmiting the values obtained when running the model to predict the trip duration for the Test dataset provided.\n",
    "\n",
    "The score function chosen by the challenge is the [root mean square logarithmic error (RMSLE)](https://www.kaggle.com/c/nyc-taxi-trip-duration#evaluation), which is defined as follows:  \n",
    "\n",
    "$$ \\epsilon = \\sqrt{ \\frac{1}{n} \\sum_{i=1}^{n} ( \\log(p_i + 1) - \\log(a_i + 1)  )^{2}    }  \\;  $$\n",
    "\n",
    "As the score function is provided we'll implement it and use the Train/Test split to evaluate our model, using it as to compare the models performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaggle_score(y_true_exp, y_pred_exp):\n",
    "    y_pred_exp = np.exp(y_pred) - 1\n",
    "    y_true_exp = np.exp(y_true) - 1\n",
    "    e_log_square = np.square( np.log(y_pred_exp + 1) - np.log(y_true_exp + 1))\n",
    "    score = np.sqrt((1/len(y_true_exp)) * np.sum(e_log_square))\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spliting the whole train dataset using train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_y_train = df_train['trip_duration']\n",
    "df_X_train = df_train.drop(columns=['trip_duration'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X_train,\n",
    "                                                    df_y_train,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "clf = model.fit(X_train, y_train)\n",
    "final_score = kaggle_score( y_test, clf.predict(X_test)\n",
    "                           \n",
    "print('Linear Regression Score: {final_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "model = Lasso(random_state=3)\n",
    "clf = model.fit(X_train, y_train)\n",
    "final_score = kaggle_score( y_test, clf.predict(X_test)\n",
    "                           \n",
    "print('Lasso Score: {final_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "model = Ridge(random_state=3)\n",
    "clf = model.fit(X_train, y_train)\n",
    "final_score = kaggle_score( y_test, clf.predict(X_test)\n",
    "                           \n",
    "print('Ridge Score: {final_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "model = ElasticNet(random_state=3, l1_ratio=0.0000001)\n",
    "clf = model.fit(X_train, y_train)\n",
    "final_score = kaggle_score( y_test, clf.predict(X_test)\n",
    "                           \n",
    "print('ElasticNet Score: {final_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model = DecisionTreeRegressor(random_state=3, max_depth=None, min_samples_split=2)\n",
    "clf = model.fit(X_train, y_train)\n",
    "final_score = kaggle_score( y_test, clf.predict(X_test)\n",
    "                           \n",
    "print('Decision Tree Regressor Score: {final_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(random_state=3)\n",
    "clf = model.fit(X_train, y_train)\n",
    "final_score = kaggle_score( y_test, clf.predict(X_test)\n",
    "                           \n",
    "print('Random Forest Regressor Score: {final_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "model = GradientBoostingRegressor(random_state=3)\n",
    "clf = model.fit(X_train, y_train)\n",
    "final_score = kaggle_score( y_test, clf.predict(X_test)\n",
    "                           \n",
    "print('Gradient Boosting Regressor Score: {final_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "model = xgb.XGBRegressor(random_state=3)\n",
    "clf = model.fit(X_train, y_train)\n",
    "final_score = kaggle_score( y_test, clf.predict(X_test)\n",
    "                           \n",
    "print('XGBoost Score: {final_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tunning the best models\n",
    "\n",
    "**Grid Search**\n",
    "\n",
    "**Cross Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models_final_score = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "model = Ridge(random_state=3)\n",
    "scorer = make_scorer(kaggle_score, greater_is_better= False)\n",
    "\n",
    "parameters = {\n",
    "    'alpha': [0.5, 5.0, 10.0, 50.0],\n",
    "    'solver': ['auto', 'lsqr', 'sag', 'svd']\n",
    "}\n",
    "clf = GridSearchCV(model, param_grid= parameters, scoring= scorer, verbose= 1, n_jobs= 6, cv= 3)\n",
    "grid_fit = clf.fit(X_train, y_train)\n",
    "\n",
    "best_params_ridge = grid_fit.best_params_\n",
    "best_clf_ridge = grid_fit.best_estimator_\n",
    "final_score = kaggle_score(y_test, best_clf_ridge.predict(X_test))\n",
    "all_models_final_score['Ridge'] = final_score\n",
    "\n",
    "print('Ridge best parameters: {best_params}')\n",
    "print('Ridge Score: {final_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "model = RandomForestRegressor(random_state=3)\n",
    "scorer = make_scorer(kaggle_score, greater_is_better= False)\n",
    "\n",
    "parameters = {\n",
    "    'max_depth': [15, 50],\n",
    "    'n_estimators': [20, 100, 200],\n",
    "    'min_samples_leaf': [1, 5, 10],\n",
    "    'min_samples_split': [2, 6, 10],\n",
    "    'max_features': ['auto', 'sqrt']\n",
    "}\n",
    "\n",
    "\n",
    "clf = GridSearchCV(model, param_grid= parameters, scoring= scorer, verbose= 1, cv= 2, n_jobs=6)\n",
    "grid_fit = clf.fit(X_train, y_train)\n",
    "\n",
    "best_params_random_forest = grid_fit.best_params_\n",
    "best_clf_random_forest = grid_fit.best_estimator_\n",
    "final_score = kaggle_score(y_test, best_clf_random_forest.predict(X_test))\n",
    "all_models_final_score['RandomForest'] = final_score\n",
    "\n",
    "print('Gradient Boosting Regressor best parameters: {best_params}')\n",
    "print('Gradient Boosting Regressor  Score: {final_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/luciano/Install/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-3630616f36b2>\", line 1, in <module>\n",
      "    from sklearn.ensemble import GradientBoostingRegressor\n",
      "  File \"/home/luciano/Install/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/__init__.py\", line 7, in <module>\n",
      "    from .forest import RandomForestClassifier\n",
      "  File \"/home/luciano/Install/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\", line 55, in <module>\n",
      "    from ..metrics import r2_score\n",
      "  File \"/home/luciano/Install/anaconda3/lib/python3.6/site-packages/sklearn/metrics/__init__.py\", line 7, in <module>\n",
      "    from .ranking import auc\n",
      "  File \"/home/luciano/Install/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py\", line 27, in <module>\n",
      "    from scipy.stats import rankdata\n",
      "  File \"/home/luciano/Install/anaconda3/lib/python3.6/site-packages/scipy/stats/__init__.py\", line 345, in <module>\n",
      "    from .stats import *\n",
      "  File \"/home/luciano/Install/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py\", line 171, in <module>\n",
      "    from . import distributions\n",
      "  File \"/home/luciano/Install/anaconda3/lib/python3.6/site-packages/scipy/stats/distributions.py\", line 10, in <module>\n",
      "    from ._distn_infrastructure import (entropy, rv_discrete, rv_continuous,\n",
      "  File \"/home/luciano/Install/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py\", line 24, in <module>\n",
      "    from scipy import optimize\n",
      "  File \"/home/luciano/Install/anaconda3/lib/python3.6/site-packages/scipy/optimize/__init__.py\", line 271, in <module>\n",
      "    from ._minimize import *\n",
      "  File \"/home/luciano/Install/anaconda3/lib/python3.6/site-packages/scipy/optimize/_minimize.py\", line 40, in <module>\n",
      "    from .slsqp import _minimize_slsqp\n",
      "  File \"/home/luciano/Install/anaconda3/lib/python3.6/site-packages/scipy/optimize/slsqp.py\", line 21, in <module>\n",
      "    from scipy.optimize._slsqp import slsqp\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luciano/Install/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2018, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luciano/Install/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/luciano/Install/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/luciano/Install/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/luciano/Install/anaconda3/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/luciano/Install/anaconda3/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/luciano/Install/anaconda3/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/luciano/Install/anaconda3/lib/python3.6/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/home/luciano/Install/anaconda3/lib/python3.6/inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/home/luciano/Install/anaconda3/lib/python3.6/inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/home/luciano/Install/anaconda3/lib/python3.6/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "model = GradientBoostingRegressor(random_state=3)\n",
    "scorer = make_scorer(kaggle_score, greater_is_better= False)\n",
    "\n",
    "parameters = {\n",
    "    'max_depth': [3, 5],\n",
    "    'n_estimators': [100, 200],\n",
    "    'min_samples_split': [2, 6],\n",
    "    'learning_rate': [0.1, 1.0]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(model, param_grid= parameters, scoring= scorer, verbose= 1, cv= 2, n_jobs=6)\n",
    "grid_fit = clf.fit(X_train, y_train)\n",
    "\n",
    "best_params_gradient_boosting = grid_fit.best_params_\n",
    "best_clf_gradient_boosting = grid_fit.best_estimator_\n",
    "final_score = kaggle_score(y_test, best_clf_gradient_boosting.predict(X_test))\n",
    "all_models_final_score['GradientBoosting'] = final_score\n",
    "\n",
    "print('Gradient Boosting Regressor best parameters: {best_params}')\n",
    "print('Gradient Boosting Regressor  Score: {final_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4e2a043d53e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_scorer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Install/anaconda3/lib/python3.6/site-packages/xgboost/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrabit\u001b[0m                   \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Install/anaconda3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSTRING_TYPES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPY3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpy_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPANDAS_INSTALLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataTable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlibpath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfind_lib_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Install/anaconda3/lib/python3.6/site-packages/xgboost/compat.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# pandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mPANDAS_INSTALLED\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Install/anaconda3/lib/python3.6/site-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_versions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tester\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Install/anaconda3/lib/python3.6/site-packages/pandas/io/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_stata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpickle\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_pickle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpackers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_msgpack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_msgpack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgbq\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_gbq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Install/anaconda3/lib/python3.6/site-packages/pandas/io/packers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternals\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minternals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsgpack\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUnpacker\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_Unpacker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPacker\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_Packer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExtType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m from pandas.util._move import (\n\u001b[1;32m     70\u001b[0m     \u001b[0mBadMove\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_BadMove\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Install/anaconda3/lib/python3.6/site-packages/pandas/io/msgpack/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsgpack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_packer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPacker\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsgpack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unpacker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munpack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpackb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnpacker\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/io/msgpack/_packer.pyx\u001b[0m in \u001b[0;36minit pandas.io.msgpack._packer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/Install/anaconda3/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "model = xgb.XGBRegressor(random_state=3)\n",
    "scorer = make_scorer(kaggle_score, greater_is_better=False)\n",
    "\n",
    "parameters = {\n",
    "    'max_depth': [5, 8, 10],\n",
    "    'n_estimators': [200, 300],\n",
    "    'learning_rate': [0.05, 0.1,],\n",
    "    'reg_lambda': [1.0, 5] }\n",
    "\n",
    "clf = GridSearchCV(model, param_grid= parameters, scoring= scorer, verbose= 1, cv=2, n_jobs=6)\n",
    "grid_fit = clf.fit(X_train, y_train)\n",
    "\n",
    "best_params_xgboost = grid_fit.best_params_\n",
    "best_clf_xgboost = grid_fit.best_estimator_\n",
    "final_score = kaggle_score(y_test, best_clf_xgboost.predict(X_test))\n",
    "all_models_final_score['XGBoost'] = final_score\n",
    "\n",
    "print('XGBoost best parameters: {best_params}')\n",
    "print('XGBoost Score: {final_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the Original Test Dataset and submitting to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "BASE_PATH_KAGGLE_SUBMISISON = './out'\n",
    "\n",
    "def create_txt_file_for_submission(df_data, file_name):\n",
    "    \n",
    "    final_path = os.path.normpath(os.path.join(BASE_PATH_KAGGLE_SUBMISISON,file_name))\n",
    "    se_subm = pd.Series(data=df_data['trip_duration'],index=df_data.index.values)\n",
    "    pd.Series.to_csv(path=file_name,\n",
    "                    sep=',',\n",
    "                    \n",
    "                    )\n",
    "    \n",
    "    np.savetxt('final_submission/name.csv',se_subm, delimiter=',',\n",
    "               comments='',\n",
    "               newline='\\n',\n",
    "               fmt='%s',\n",
    "               header = 'id,trip_duration')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
