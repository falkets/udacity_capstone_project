{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_overall_model = best_models['XGBoost']\n",
    "state_avg = []\n",
    "state_std = []\n",
    "state_score = []\n",
    "for i in range(10):\n",
    "    print(f'Runing Iteration {i}')\n",
    "    random_state = np.random.randint(low=0, high=100)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_X_train,\n",
    "                                                        df_y_train,\n",
    "                                                        test_size = 0.3,\n",
    "                                                        random_state = random_state)\n",
    "    clf = sklearn.base.clone(best_overall_model['clf'])\n",
    "    clf.random_state = random_state\n",
    "    clf.nthread=6\n",
    "    clf.fit(df_X_train, df_y_train)\n",
    "    y_predict = clf.predict(X_test)\n",
    "    \n",
    "    state_score.append(kaggle_score(y_test, y_predict))\n",
    "    y_predict = np.exp(y_predict) - 1\n",
    "    state_avg.append(y_predict.mean())\n",
    "    state_std.append(y_predict.std())\n",
    "\n",
    "df_result_free = pd.DataFrame(\n",
    "    {'state_score': state_score,\n",
    "     'state_avg': state_avg,\n",
    "     'state_std': state_std\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import sklearn\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import xgboost as xgb\n",
    "import scipy\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "PATH_TRAIN_DATASET = './data/train.csv'\n",
    "PATH_TEST_DATASET = './data/test.csv'\n",
    "PATH_SAMPLE_SUMBISSION = './data/sample_submission.csv'\n",
    "\n",
    "NYC_DEGREE_KM = 111.05938787411571\n",
    "NYC_BOUNDING_BOX = [(40.4774,-74.2589), ( 40.9176, -73.7004)]\n",
    "\n",
    "def calculate_city_block_distance(df_data):\n",
    "    delta_lat = np.absolute(df_data.pickup_latitude - df_data.dropoff_latitude) * NYC_DEGREE_KM    \n",
    "    delta_lon = np.absolute(df_data.pickup_longitude - df_data.dropoff_longitude) * NYC_DEGREE_KM    \n",
    "    return delta_lat + delta_lon\n",
    "\n",
    "def kaggle_score(y_true_exp, y_pred_exp):\n",
    "    y_pred_exp = np.exp(y_pred_exp) - 1\n",
    "    y_true_exp = np.exp(y_true_exp) - 1\n",
    "    e_log_square = np.square( np.log(y_pred_exp + 1) - np.log(y_true_exp + 1))\n",
    "    score = np.sqrt((1/len(y_true_exp)) * np.sum(e_log_square))\n",
    "    return score\n",
    "\n",
    "df_test = pd.read_csv(PATH_TEST_DATASET, infer_datetime_format=True, parse_dates=['pickup_datetime'],  index_col='id')\n",
    "df_train = pd.read_csv(PATH_TRAIN_DATASET, infer_datetime_format=True,parse_dates=['pickup_datetime'], index_col='id')\n",
    "\n",
    "df_train.drop('dropoff_datetime', axis=1, inplace=True)\n",
    "df_train['pickup_datetime'] = df_train['pickup_datetime'].dt.to_pydatetime()\n",
    "df_test['pickup_datetime'] = df_test['pickup_datetime'].dt.to_pydatetime()\n",
    "\n",
    "Q1 = df_train['trip_duration'].quantile(0.25)\n",
    "Q3 = df_train['trip_duration'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "df_train = df_train[~((df_train['trip_duration'] < (Q1 - 1.5 * IQR)) |(df_train['trip_duration'] > (Q3 + 1.5 * IQR)))]\n",
    "\n",
    "df_train = df_train[df_train['trip_duration'] > 1]\n",
    "df_train = df_train[df_train['trip_duration'] < 7200]\n",
    "\n",
    "filter_lat_long = df_train['pickup_latitude'] < NYC_BOUNDING_BOX[1][0]\n",
    "filter_lat_long &= df_train['pickup_latitude'] > NYC_BOUNDING_BOX[0][0]\n",
    "filter_lat_long &= df_train['pickup_longitude'] < NYC_BOUNDING_BOX[1][1]\n",
    "filter_lat_long &= df_train['pickup_longitude'] > NYC_BOUNDING_BOX[0][1]\n",
    "\n",
    "filter_lat_long &= df_train['dropoff_latitude'] < NYC_BOUNDING_BOX[1][0]\n",
    "filter_lat_long &= df_train['dropoff_latitude'] > NYC_BOUNDING_BOX[0][0]\n",
    "filter_lat_long &= df_train['dropoff_longitude'] < NYC_BOUNDING_BOX[1][1]\n",
    "filter_lat_long &= df_train['dropoff_longitude'] > NYC_BOUNDING_BOX[0][1]\n",
    "\n",
    "\n",
    "df_train['distance'] = calculate_city_block_distance(df_train)\n",
    "df_train = df_train[df_train['distance'] > .1]\n",
    "df_train['avg_speed'] = df_train['distance']/(df_train['trip_duration']/3600)\n",
    "df_train = df_train[df_train['avg_speed'] < 100]\n",
    "df_train = df_train[df_train['avg_speed'] > 1]\n",
    "\n",
    "df_train.drop('avg_speed', axis=1, inplace=True)\n",
    "\n",
    "df_train['pickup_date'] = df_train['pickup_datetime'].dt.date\n",
    "df_train['pickup_hour'] = df_train['pickup_datetime'].dt.hour\n",
    "df_train['pickup_weekday'] = df_train['pickup_datetime'].dt.day_name()\n",
    "\n",
    "holidays = [day.date() for day in calendar().holidays(start=df_train['pickup_date'].min(), end=df_train['pickup_date'].max())]\n",
    "df_train['holiday'] = df_train['pickup_date'].isin(holidays)\n",
    "df_train.drop('pickup_date', axis=1, inplace=True)\n",
    "\n",
    "df_train = df_train[df_train['passenger_count']>0]\n",
    "\n",
    "df_train = pd.get_dummies(df_train, columns=['vendor_id', 'passenger_count', \n",
    "                                    'store_and_fwd_flag', 'pickup_weekday', 'pickup_hour', 'holiday'])\n",
    "\n",
    "cols = ['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']\n",
    "df_train[cols] = df_train[cols].round(3)\n",
    "\n",
    "df_train.drop(['pickup_datetime'], axis=1, inplace=True)\n",
    "\n",
    "df_train['trip_duration'] = np.log(df_train['trip_duration'] + 1)\n",
    "df_train['distance'] = np.log(df_train['distance'] + 1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_y_train = df_train['trip_duration']\n",
    "df_X_train = df_train.drop(columns=['trip_duration'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X_train,\n",
    "                                                    df_y_train,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state = 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating RMSLE on the test set with LinearRegression\n",
      "0.4164895901671564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4136468008174538"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "clf = model.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print('Estimating RMSLE on the test set with LinearRegression')\n",
    "print(kaggle_score( y_test, y_pred))\n",
    "0.4136468008174538"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating RMSLE on the test set with LinearRegression\n",
      "0.4164895901671564\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "clf = model.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print('Estimating RMSLE on the test set with LinearRegression')\n",
    "print(kaggle_score( y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating RMSLE on the test set with Lasso\n",
      "0.6736416145430251\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "model = Lasso(random_state=3)\n",
    "clf = model.fit(X_train, y_train)\n",
    "print('Estimating RMSLE on the test set with Lasso')\n",
    "print(kaggle_score( y_test, clf.predict(X_test) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating RMSLE on the test set with Lasso\n",
      "0.41649015670802203\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "model = Ridge(random_state=3)\n",
    "clf = model.fit(X_train, y_train)\n",
    "print('Estimating RMSLE on the test set with Lasso')\n",
    "print(kaggle_score( y_test, clf.predict(X_test) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating RMSLE on the test set with Lasso\n",
      "0.5824324330743528\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "model = ElasticNet(random_state=3, l1_ratio=0.0000001)\n",
    "clf = model.fit(X_train, y_train)\n",
    "print('Estimating RMSLE on the test set with Lasso')\n",
    "print(kaggle_score( y_test, clf.predict(X_test) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating RMSLE on the test set with Lasso\n",
      "0.46676467032269114\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model = DecisionTreeRegressor(random_state=3, max_depth=None, min_samples_split=2)\n",
    "clf = model.fit(X_train, y_train)\n",
    "print('Estimating RMSLE on the test set with Lasso')\n",
    "print(kaggle_score( y_test, clf.predict(X_test) ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luciano/Install/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating RMSLE on the test set with Lasso\n",
      "0.34154495163660903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.45528085083412867"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(random_state=3)\n",
    "clf = model.fit(X_train, y_train)\n",
    "print('Estimating RMSLE on the test set with Lasso')\n",
    "print(kaggle_score( y_test, clf.predict(X_test) ) )\n",
    "0.45528085083412867"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating RMSLE on the test set with Lasso\n",
      "0.3923103353785279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.40792254444974163"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "model = GradientBoostingRegressor(random_state=3)\n",
    "clf = model.fit(X_train, y_train)\n",
    "print('Estimating RMSLE on the test set with Lasso')\n",
    "print(kaggle_score( y_test, clf.predict(X_test) ) )\n",
    "0.40792254444974163"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating RMSLE on the test set with Lasso\n",
      "0.39225595593255225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4080742167350305"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "model = xgb.XGBRegressor(random_state=3)\n",
    "clf = model.fit(X_train, y_train)\n",
    "print('Estimating RMSLE on the test set with Lasso')\n",
    "print(kaggle_score( y_test, clf.predict(X_test) ) )\n",
    "0.4080742167350305"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   26.3s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   35.4s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   53.7s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.2min\n",
      "/home/luciano/Install/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  48 | elapsed:  1.6min remaining:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.1, 'solver': 'auto'}\n",
      "0.416490182506801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.41648924466344467"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# greater_is_better= False: we want to minimize the root mean square logarithmic error\n",
    "scorer = make_scorer(kaggle_score, greater_is_better= False)\n",
    "\n",
    "model = Ridge(random_state=3)\n",
    "\n",
    "parameters = {'alpha': [0.1, 5.0, 10.0, 50.0], 'solver': ['auto', 'lsqr', 'sag', 'svd']}\n",
    "# parameters = {'alpha': [0.1], 'solver': ['sag']}\n",
    "\n",
    "clf = GridSearchCV(model, param_grid= parameters, scoring= scorer, verbose= 10, n_jobs=-1, cv= 3)\n",
    "\n",
    "grid_fit = clf.fit(X_train, y_train)\n",
    "\n",
    "print(grid_fit.best_params_)\n",
    "best_clf_ridge = grid_fit.best_estimator_\n",
    "\n",
    "print(kaggle_score( y_test, best_clf_ridge.predict(X_test) ) )\n",
    "0.41648924466344467"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 16 candidates, totalling 32 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed: 29.4min\n",
      "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed: 38.3min\n",
      "[Parallel(n_jobs=6)]: Done  25 out of  32 | elapsed: 49.0min remaining: 13.7min\n",
      "[Parallel(n_jobs=6)]: Done  29 out of  32 | elapsed: 58.2min remaining:  6.0min\n",
      "[Parallel(n_jobs=6)]: Done  32 out of  32 | elapsed: 62.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 1.0, 'max_depth': 5, 'min_samples_split': 6, 'n_estimators': 200}\n",
      "0.3325317765694744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.35810574107314747"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "model = GradientBoostingRegressor(random_state=3)\n",
    "scorer = make_scorer(kaggle_score, greater_is_better= False)\n",
    "\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'max_depth': [3, 5],\n",
    "    'n_estimators': [100, 200],\n",
    "    'min_samples_split': [2, 6],\n",
    "    'learning_rate': [0.1, 1.0]\n",
    "}\n",
    "\n",
    "# parameters = {'learning_rate': [0.1], 'max_depth': [5], 'min_samples_split': [6], 'n_estimators': [200]}\n",
    "\n",
    "clf = GridSearchCV(model, param_grid= parameters, scoring= scorer, verbose= 10, cv= 2, n_jobs=6)\n",
    "\n",
    "grid_fit = clf.fit(X_train, y_train)\n",
    "\n",
    "print(grid_fit.best_params_)\n",
    "best_clf_gradient_boosting = grid_fit.best_estimator_\n",
    "\n",
    "print(kaggle_score( y_test, best_clf_gradient_boosting.predict(X_test) ) )\n",
    "0.35810574107314747"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 24 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed: 14.1min\n",
      "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed: 48.8min\n",
      "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed: 71.8min\n",
      "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed: 96.0min\n",
      "[Parallel(n_jobs=6)]: Done  42 out of  48 | elapsed: 129.9min remaining: 18.6min\n",
      "[Parallel(n_jobs=6)]: Done  48 out of  48 | elapsed: 150.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300, 'reg_lambda': 5}\n",
      "0.3140347959375159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.34973122433139087"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# greater_is_better= False: we want to minimize the root mean square logarithmic error\n",
    "scorer = make_scorer(kaggle_score, greater_is_better=False)\n",
    "\n",
    "model = xgb.XGBRegressor(random_state=3)\n",
    "\n",
    "parameters = {'max_depth': [5, 8, 10], 'n_estimators': [200, 300],\n",
    "              'learning_rate': [0.05, 0.1,], 'reg_lambda': [1.0, 5] }\n",
    "# parameters = {'learning_rate': [0.1], 'max_depth': [5], 'n_estimators': [300], 'reg_lambda': [5]}\n",
    "clf = GridSearchCV(model, param_grid= parameters, scoring= scorer, verbose= 10, cv=2, n_jobs=6)\n",
    "\n",
    "grid_fit = clf.fit(X_train, y_train)\n",
    "\n",
    "print(grid_fit.best_params_)\n",
    "best_clf_xgboost = grid_fit.best_estimator_\n",
    "\n",
    "print(kaggle_score( y_test, best_clf_xgboost.predict(X_test) ) )\n",
    "0.34973122433139087"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(PATH_TEST_DATASET, infer_datetime_format=True, parse_dates=['pickup_datetime'],  index_col='id')\n",
    "# df_test['pickup_datetime'] = df_test['pickup_datetime'].dt.to_pydatetime()\n",
    "df_test['pickup_date'] = df_test['pickup_datetime'].dt.date\n",
    "df_test['pickup_hour'] = df_test['pickup_datetime'].dt.hour\n",
    "df_test['pickup_weekday'] = df_test['pickup_datetime'].dt.day_name()\n",
    "\n",
    "holidays = [day.date() for day in calendar().holidays(start=df_test['pickup_date'].min(), end=df_test['pickup_date'].max())]\n",
    "df_test['holiday'] = df_test['pickup_date'].isin(holidays)\n",
    "df_test.drop('pickup_date', axis=1, inplace=True)\n",
    "df_test['distance'] = calculate_city_block_distance(df_test)\n",
    "df_test['distance'] = np.log(df_test['distance'] + 1)\n",
    "\n",
    "df_test = pd.get_dummies(df_test, columns=['vendor_id', 'passenger_count', \n",
    "                                    'store_and_fwd_flag', 'pickup_weekday', 'pickup_hour', 'holiday'])\n",
    "# df_test.drop(['pickup_datetime', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude'], axis=1, inplace=True)\n",
    "df_test.drop(['passenger_count_0', 'passenger_count_9'], axis=1, inplace=True)\n",
    "df_test.drop(['pickup_datetime'], axis=1, inplace=True)\n",
    "cols = ['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']\n",
    "df_test[cols] = df_test[cols].round(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['vendor_id', 'pickup_datetime', 'dropoff_datetime', 'passenger_count',\n",
       "       'pickup_longitude', 'pickup_latitude', 'dropoff_longitude',\n",
       "       'dropoff_latitude', 'store_and_fwd_flag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['dropoff_datetime'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-4973267bd4e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdf_X_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pickup_datetime'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dropoff_datetime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pickup_datetime'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dropoff_datetime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m X_train, X_test, y_train, y_test = train_test_split(df_X_train,\n\u001b[1;32m     10\u001b[0m                                                     \u001b[0mdf_y_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Install/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3695\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3696\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3697\u001b[0;31m                                            errors=errors)\n\u001b[0m\u001b[1;32m   3698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3699\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[0;32m~/Install/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3109\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3110\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3111\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Install/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3141\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3143\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3144\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Install/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   4402\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4403\u001b[0m                 raise KeyError(\n\u001b[0;32m-> 4404\u001b[0;31m                     '{} not found in axis'.format(labels[mask]))\n\u001b[0m\u001b[1;32m   4405\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4406\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['dropoff_datetime'] not found in axis\""
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(PATH_TRAIN_DATASET, infer_datetime_format=True,parse_dates=['pickup_datetime'], index_col='id')\n",
    "df_test = pd.read_csv(PATH_TEST_DATASET, infer_datetime_format=True, parse_dates=['pickup_datetime'],  index_col='id')\n",
    "\n",
    "df_X_train.drop(['pickup_datetime', 'dropoff_datetime'], axis=1, inplace=True)\n",
    "df_test.drop(['pickup_datetime', 'dropoff_datetime'], axis=1, inplace=True)\n",
    "\n",
    "df_y_train = df_train['trip_duration']\n",
    "df_X_train = df_train.drop(columns=['trip_duration'])\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "clf = model.fit(df_X_train, df_y_train)\n",
    "y_predict = clf.predict(df_test)\n",
    "y_predict = np.exp(y_predict) - 1\n",
    "df_result = pd.DataFrame(y_predict, columns=['trip_duration'], index=df_test.index.values)\n",
    "create_txt_file_for_submission(df_result, 'LinearRegression')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_clf_xgboost' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-874818d496a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m                   )\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mfinal_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_clf_xgboost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mfinal_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_y_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'xgboost_latlong'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_clf_xgboost' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "BASE_PATH_KAGGLE_SUBMISISON = './out'\n",
    "\n",
    "def create_txt_file_for_submission(df_data, file_name):\n",
    "    \n",
    "    final_path = os.path.abspath(os.path.join(BASE_PATH_KAGGLE_SUBMISISON,file_name))\n",
    "    final_path += '.txt'\n",
    "    df_data.index.name = 'id'\n",
    "    print(final_path)\n",
    "    df_data.to_csv(final_path,\n",
    "                   sep=',',\n",
    "                   header=True,\n",
    "                   na_rep=df_data['trip_duration'].quantile(0.5)\n",
    "                  )\n",
    "    \n",
    "final_clf = sklearn.base.clone(best_clf_xgboost)\n",
    "final_clf.fit(df_X_train, df_y_train)\n",
    "model_name='xgboost_latlong'\n",
    "y_predict = final_clf.predict(df_test)\n",
    "y_predict = np.exp(y_predict) - 1\n",
    "df_result = pd.DataFrame(y_predict, columns=['trip_duration'], index=df_test.index.values)\n",
    "create_txt_file_for_submission(df_result, model_name)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final: 0.42976"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
