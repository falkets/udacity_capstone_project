{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import xgboost as xgb\n",
    "import scipy\n",
    "from geopy import distance\n",
    "import geopy\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "plt.rcParams['figure.figsize'] = [16, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYC_DEGREE_KM = 111.05938787411571\n",
    "\n",
    "def calculate_city_block_distance(df_data):\n",
    "    delta_lat = np.absolute(df_data.pickup_latitude - df_data.dropoff_latitude) * NYC_DEGREE_KM    \n",
    "    delta_lon = np.absolute(df_data.pickup_longitude - df_data.dropoff_longitude) * NYC_DEGREE_KM    \n",
    "    return delta_lat + delta_lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TRAIN_DATASET = './data/train.csv'\n",
    "PATH_TEST_DATASET = './data/test.csv'\n",
    "PATH_SAMPLE_SUMBISSION = './data/sample_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_train.head()\n",
    "except:\n",
    "    df_test = pd.read_csv(PATH_TEST_DATASET, infer_datetime_format=True, parse_dates=['pickup_datetime'],  index_col='id')\n",
    "    df_train = pd.read_csv(PATH_TRAIN_DATASET, infer_datetime_format=True,parse_dates=['pickup_datetime'], index_col='id')\n",
    "    df_sample_submission = pd.read_csv(PATH_SAMPLE_SUMBISSION)\n",
    "    \n",
    "    df_train.drop('dropoff_datetime', axis=1, inplace=True)\n",
    "    df_train['pickup_datetime'] = df_train['pickup_datetime'].dt.to_pydatetime()\n",
    "    df_test['pickup_datetime'] = df_test['pickup_datetime'].dt.to_pydatetime()\n",
    "    \n",
    "    df_train['pickup_date'] = df_train['pickup_datetime'].dt.date\n",
    "    df_train['pickup_hour'] = df_train['pickup_datetime'].dt.hour\n",
    "    df_train['pickup_weekday'] = df_train['pickup_datetime'].dt.day_name()\n",
    "\n",
    "    holidays = [day.date() for day in calendar().holidays(start=df_train['pickup_date'].min(), end=df_train['pickup_date'].max())]\n",
    "    df_train['holiday'] = df_train['pickup_date'].isin(holidays)\n",
    "    df_train.drop('pickup_date', axis=1, inplace=True)\n",
    "    \n",
    "    df_train['distance'] = calculate_city_block_distance(df_train)\n",
    "    df_train['avg_speed'] = df_train['distance']/(df_train['trip_duration']/3600)\n",
    "    df_original_train = df_train.copy()\n",
    "    df_original_test = df_test.copy()\n",
    "finally:\n",
    "    df_train = df_original_train.copy()\n",
    "    df_test = df_original_test.copy()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.384424e+06\n",
       "mean     7.317026e+02\n",
       "std      4.481081e+02\n",
       "min      1.000000e+00\n",
       "25%      3.840000e+02\n",
       "50%      6.320000e+02\n",
       "75%      9.910000e+02\n",
       "max      2.092000e+03\n",
       "Name: trip_duration, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q1 = df_train['trip_duration'].quantile(0.25)\n",
    "Q3 = df_train['trip_duration'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "df_train = df_train[~((df_train['trip_duration'] < (Q1 - 1.5 * IQR)) |(df_train['trip_duration'] > (Q3 + 1.5 * IQR)))]\n",
    "df_train['trip_duration'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYC_BOUNDING_BOX = [(40.4774,-74.2589), ( 40.9176, -73.7004)]\n",
    "\n",
    "filter_lat_long = df_train['pickup_latitude'] < NYC_BOUNDING_BOX[1][0]\n",
    "filter_lat_long &= df_train['pickup_latitude'] > NYC_BOUNDING_BOX[0][0]\n",
    "filter_lat_long &= df_train['pickup_longitude'] < NYC_BOUNDING_BOX[1][1]\n",
    "filter_lat_long &= df_train['pickup_longitude'] > NYC_BOUNDING_BOX[0][1]\n",
    "\n",
    "filter_lat_long &= df_train['dropoff_latitude'] < NYC_BOUNDING_BOX[1][0]\n",
    "filter_lat_long &= df_train['dropoff_latitude'] > NYC_BOUNDING_BOX[0][0]\n",
    "filter_lat_long &= df_train['dropoff_longitude'] < NYC_BOUNDING_BOX[1][1]\n",
    "filter_lat_long &= df_train['dropoff_longitude'] > NYC_BOUNDING_BOX[0][1]\n",
    "\n",
    "df_train = df_train[filter_lat_long]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train['avg_speed'] < 100]\n",
    "df_train = df_train[df_train['avg_speed'] > 1]\n",
    "df_train = df_train[df_train['distance'] > .25]\n",
    "\n",
    "df_train = df_train[df_train['trip_duration'] > 1]\n",
    "df_train = df_train[df_train['trip_duration'] < 7200]\n",
    "\n",
    "df_train.drop('avg_speed', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train['passenger_count'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.get_dummies(df_train, columns=['vendor_id', 'passenger_count', \n",
    "                                    'store_and_fwd_flag', 'pickup_weekday', 'pickup_hour', 'holiday'])\n",
    "df_train.drop(['pickup_datetime', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['trip_duration'] = np.log(df_train['trip_duration'] + 1)\n",
    "df_train['distance'] = np.log(df_train['distance'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaggle_score(y_true, y_pred):\n",
    "    y_pred_exp = np.exp(y_pred) - 1\n",
    "    y_true_exp = np.exp(y_true) - 1\n",
    "    e_log_square = np.square( np.log(y_pred_exp + 1) - np.log( y_true_exp + 1) )\n",
    "    score = np.sqrt( (1/len(y_true_exp)) * np.sum(e_log_square) )\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_y_train = df_train['trip_duration']\n",
    "df_X_train = df_train.drop(columns=['trip_duration'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X_train,\n",
    "                                                        df_y_train,\n",
    "                                                        test_size = 0.3,\n",
    "                                                        random_state = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating RMSLE on the test set with LinearRegression\n",
      "0.42544939377656404\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "clf = model.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print('Estimating RMSLE on the test set with LinearRegression')\n",
    "print(kaggle_score( y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating RMSLE on the test set with Lasso\n",
      "0.6674914761366839\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "model = Lasso(random_state=3)\n",
    "clf = model.fit(X_train, y_train)\n",
    "print('Estimating RMSLE on the test set with Lasso')\n",
    "print(kaggle_score( y_test, clf.predict(X_test) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating RMSLE on the test set with Lasso\n",
      "0.4254494827225051\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "model = Ridge(random_state=3)\n",
    "clf = model.fit(X_train, y_train)\n",
    "print('Estimating RMSLE on the test set with Lasso')\n",
    "print(kaggle_score( y_test, clf.predict(X_test) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating RMSLE on the test set with Lasso\n",
      "0.5780364160563632\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "model = ElasticNet(random_state=3, l1_ratio=0.0000001)\n",
    "clf = model.fit(X_train, y_train)\n",
    "print('Estimating RMSLE on the test set with Lasso')\n",
    "print(kaggle_score( y_test, clf.predict(X_test) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating RMSLE on the test set with Lasso\n",
      "0.5661372918817497\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model = DecisionTreeRegressor(random_state=3, max_depth=None, min_samples_split=2)\n",
    "clf = model.fit(X_train, y_train)\n",
    "print('Estimating RMSLE on the test set with Lasso')\n",
    "print(kaggle_score( y_test, clf.predict(X_test) ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luciano/Install/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating RMSLE on the test set with Lasso\n",
      "0.45528085083412867\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(random_state=3)\n",
    "clf = model.fit(X_train, y_train)\n",
    "print('Estimating RMSLE on the test set with Lasso')\n",
    "print(kaggle_score( y_test, clf.predict(X_test) ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating RMSLE on the test set with Lasso\n",
      "0.40792254444974163\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "model = GradientBoostingRegressor(random_state=3)\n",
    "clf = model.fit(X_train, y_train)\n",
    "print('Estimating RMSLE on the test set with Lasso')\n",
    "print(kaggle_score( y_test, clf.predict(X_test) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating RMSLE on the test set with Lasso\n",
      "0.4080742167350305\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "model = xgb.XGBRegressor(random_state=3)\n",
    "clf = model.fit(X_train, y_train)\n",
    "print('Estimating RMSLE on the test set with Lasso')\n",
    "print(kaggle_score( y_test, clf.predict(X_test) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   23.8s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   33.8s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   52.9s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  48 | elapsed:  1.5min remaining:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 50.0, 'solver': 'sag'}\n",
      "0.4254512103471298\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# greater_is_better= False: we want to minimize the root mean square logarithmic error\n",
    "scorer = make_scorer(kaggle_score, greater_is_better= False)\n",
    "\n",
    "model = Ridge(random_state=3)\n",
    "\n",
    "parameters = {'alpha': [0.1, 5.0, 10.0, 50.0], 'solver': ['auto', 'lsqr', 'sag', 'svd']}\n",
    "\n",
    "clf = GridSearchCV(model, param_grid= parameters, scoring= scorer, verbose= 10, n_jobs=-1, cv= 3)\n",
    "\n",
    "grid_fit = clf.fit(X_train, y_train)\n",
    "\n",
    "print(grid_fit.best_params_)\n",
    "best_clf_ridge = grid_fit.best_estimator_\n",
    "\n",
    "print(kaggle_score( y_test, best_clf_ridge.predict(X_test) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 24 candidates, totalling 48 fits\n",
      "[CV] max_depth=50, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=150 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/falkets/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-16-ce1bd4544dc6>\", line 14, in <module>\n",
      "    grid_fit = clf.fit(X_train, y_train)\n",
      "  File \"/home/falkets/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\", line 722, in fit\n",
      "    self._run_search(evaluate_candidates)\n",
      "  File \"/home/falkets/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\", line 1191, in _run_search\n",
      "    evaluate_candidates(ParameterGrid(self.param_grid))\n",
      "  File \"/home/falkets/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\", line 711, in evaluate_candidates\n",
      "    cv.split(X, y, groups)))\n",
      "  File \"/home/falkets/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 917, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/falkets/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/falkets/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/falkets/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 182, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/falkets/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 549, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/falkets/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 225, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/falkets/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 225, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/falkets/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 568, in _fit_and_score\n",
      "    test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n",
      "  File \"/home/falkets/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 605, in _score\n",
      "    return _multimetric_score(estimator, X_test, y_test, scorer)\n",
      "  File \"/home/falkets/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 635, in _multimetric_score\n",
      "    score = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/falkets/anaconda3/lib/python3.6/site-packages/sklearn/metrics/scorer.py\", line 91, in __call__\n",
      "    y_pred = estimator.predict(X)\n",
      "  File \"/home/falkets/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\", line 704, in predict\n",
      "    for e in self.estimators_)\n",
      "  File \"/home/falkets/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 920, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"/home/falkets/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/falkets/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/falkets/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 182, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/falkets/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 549, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/falkets/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 225, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/falkets/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 225, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/falkets/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\", line 389, in _accumulate_prediction\n",
      "    prediction = predict(X, check_input=False)\n",
      "  File \"/home/falkets/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py\", line 417, in predict\n",
      "    proba = self.tree_.predict(X)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/falkets/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2018, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/falkets/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/falkets/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/falkets/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/falkets/anaconda3/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/falkets/anaconda3/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/falkets/anaconda3/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/falkets/anaconda3/lib/python3.6/inspect.py\", line 732, in getmodule\n",
      "    for modname, module in list(sys.modules.items()):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "model = RandomForestRegressor(random_state=3)\n",
    "scorer = make_scorer(kaggle_score, greater_is_better= False)\n",
    "\n",
    "parameters = {'max_depth': [50, 80], 'n_estimators': [150, 250], 'min_samples_leaf': [1, 2, 3],\n",
    "              'min_samples_split': [2, 3], 'max_features': ['auto']}\n",
    "\n",
    "\n",
    "clf = GridSearchCV(model, param_grid= parameters, scoring= scorer, verbose= 10, cv=2, n_jobs=1)\n",
    "\n",
    "grid_fit = clf.fit(X_train, y_train)\n",
    "\n",
    "print(grid_fit.best_params_)\n",
    "best_clf_random_forest = grid_fit.best_estimator_\n",
    "\n",
    "print(kaggle_score( y_test, best_clf_random_forest.predict(X_test) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "model = GradientBoostingRegressor(random_state=3)\n",
    "scorer = make_scorer(kaggle_score, greater_is_better= False)\n",
    "\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'max_depth': [3, 5],\n",
    "    'n_estimators': [100, 200],\n",
    "    'min_samples_split': [2, 6],\n",
    "    'learning_rate': [0.1, 1.0]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(model, param_grid= parameters, scoring= scorer, verbose= 10, cv= 2, n_jobs=6)\n",
    "\n",
    "grid_fit = clf.fit(X_train, y_train)\n",
    "\n",
    "print(grid_fit.best_params_)\n",
    "best_clf_gradient_boosting = grid_fit.best_estimator_\n",
    "\n",
    "print(kaggle_score( y_test, best_clf_gradient_boosting.predict(X_test) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# greater_is_better= False: we want to minimize the root mean square logarithmic error\n",
    "scorer = make_scorer(kaggle_score, greater_is_better=False)\n",
    "\n",
    "model = xgb.XGBRegressor(random_state=3)\n",
    "\n",
    "parameters = {'max_depth': [5, 8, 10], 'n_estimators': [200, 300],\n",
    "              'learning_rate': [0.05, 0.1,], 'reg_lambda': [1.0, 5] }\n",
    "\n",
    "clf = GridSearchCV(model, param_grid= parameters, scoring= scorer, verbose= 10, cv=2, n_jobs=6)\n",
    "\n",
    "grid_fit = clf.fit(X_train, y_train)\n",
    "\n",
    "print(grid_fit.best_params_)\n",
    "best_clf_xgboost = grid_fit.best_estimator_\n",
    "\n",
    "print(kaggle_score( y_test, best_clf_xgboost.predict(X_test) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
