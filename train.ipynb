{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import sklearn\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import xgboost as xgb\n",
    "import scipy\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "PATH_TRAIN_DATASET = './data/train.csv'\n",
    "PATH_TEST_DATASET = './data/test.csv'\n",
    "PATH_SAMPLE_SUMBISSION = './data/sample_submission.csv'\n",
    "\n",
    "NYC_DEGREE_KM = 111.05938787411571\n",
    "NYC_BOUNDING_BOX = [(40.4774,-74.2589), ( 40.9176, -73.7004)]\n",
    "\n",
    "def calculate_city_block_distance(df_data):\n",
    "    delta_lat = np.absolute(df_data.pickup_latitude - df_data.dropoff_latitude) * NYC_DEGREE_KM    \n",
    "    delta_lon = np.absolute(df_data.pickup_longitude - df_data.dropoff_longitude) * NYC_DEGREE_KM    \n",
    "    return delta_lat + delta_lon\n",
    "\n",
    "def kaggle_score(y_true_exp, y_pred_exp):\n",
    "    y_pred_exp = np.exp(y_pred_exp) - 1\n",
    "    y_true_exp = np.exp(y_true_exp) - 1\n",
    "    e_log_square = np.square( np.log(y_pred_exp + 1) - np.log(y_true_exp + 1))\n",
    "    score = np.sqrt((1/len(y_true_exp)) * np.sum(e_log_square))\n",
    "    return score\n",
    "\n",
    "df_test = pd.read_csv(PATH_TEST_DATASET, infer_datetime_format=True, parse_dates=['pickup_datetime'],  index_col='id')\n",
    "df_train = pd.read_csv(PATH_TRAIN_DATASET, infer_datetime_format=True,parse_dates=['pickup_datetime'], index_col='id')\n",
    "\n",
    "df_train.drop('dropoff_datetime', axis=1, inplace=True)\n",
    "df_train['pickup_datetime'] = df_train['pickup_datetime'].dt.to_pydatetime()\n",
    "df_test['pickup_datetime'] = df_test['pickup_datetime'].dt.to_pydatetime()\n",
    "\n",
    "Q1 = df_train['trip_duration'].quantile(0.25)\n",
    "Q3 = df_train['trip_duration'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "df_train = df_train[~((df_train['trip_duration'] < (Q1 - 1.5 * IQR)) |(df_train['trip_duration'] > (Q3 + 1.5 * IQR)))]\n",
    "\n",
    "df_train = df_train[df_train['trip_duration'] > 1]\n",
    "df_train = df_train[df_train['trip_duration'] < 7200]\n",
    "\n",
    "filter_lat_long = df_train['pickup_latitude'] < NYC_BOUNDING_BOX[1][0]\n",
    "filter_lat_long &= df_train['pickup_latitude'] > NYC_BOUNDING_BOX[0][0]\n",
    "filter_lat_long &= df_train['pickup_longitude'] < NYC_BOUNDING_BOX[1][1]\n",
    "filter_lat_long &= df_train['pickup_longitude'] > NYC_BOUNDING_BOX[0][1]\n",
    "\n",
    "filter_lat_long &= df_train['dropoff_latitude'] < NYC_BOUNDING_BOX[1][0]\n",
    "filter_lat_long &= df_train['dropoff_latitude'] > NYC_BOUNDING_BOX[0][0]\n",
    "filter_lat_long &= df_train['dropoff_longitude'] < NYC_BOUNDING_BOX[1][1]\n",
    "filter_lat_long &= df_train['dropoff_longitude'] > NYC_BOUNDING_BOX[0][1]\n",
    "\n",
    "\n",
    "df_train['distance'] = calculate_city_block_distance(df_train)\n",
    "df_train = df_train[df_train['distance'] > .1]\n",
    "df_train['avg_speed'] = df_train['distance']/(df_train['trip_duration']/3600)\n",
    "df_train = df_train[df_train['avg_speed'] < 100]\n",
    "df_train = df_train[df_train['avg_speed'] > 1]\n",
    "\n",
    "df_train.drop('avg_speed', axis=1, inplace=True)\n",
    "\n",
    "df_train['pickup_date'] = df_train['pickup_datetime'].dt.date\n",
    "df_train['pickup_hour'] = df_train['pickup_datetime'].dt.hour\n",
    "df_train['pickup_weekday'] = df_train['pickup_datetime'].dt.day_name()\n",
    "\n",
    "holidays = [day.date() for day in calendar().holidays(start=df_train['pickup_date'].min(), end=df_train['pickup_date'].max())]\n",
    "df_train['holiday'] = df_train['pickup_date'].isin(holidays)\n",
    "df_train.drop('pickup_date', axis=1, inplace=True)\n",
    "\n",
    "df_train = df_train[df_train['passenger_count']>0]\n",
    "\n",
    "df_train = pd.get_dummies(df_train, columns=['vendor_id', 'passenger_count', \n",
    "                                    'store_and_fwd_flag', 'pickup_weekday', 'pickup_hour', 'holiday'])\n",
    "\n",
    "cols = ['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']\n",
    "df_train[cols] = df_train[cols].round(3)\n",
    "\n",
    "df_train.drop(['pickup_datetime'], axis=1, inplace=True)\n",
    "\n",
    "df_train['trip_duration'] = np.log(df_train['trip_duration'] + 1)\n",
    "df_train['distance'] = np.log(df_train['distance'] + 1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_y_train = df_train['trip_duration']\n",
    "df_X_train = df_train.drop(columns=['trip_duration'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X_train,\n",
    "                                                    df_y_train,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state = 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating RMSLE on the test set with LinearRegression\n",
      "0.4164895901671564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4136468008174538"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "clf = model.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print('Estimating RMSLE on the test set with LinearRegression')\n",
    "print(kaggle_score( y_test, y_pred))\n",
    "0.4136468008174538"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating RMSLE on the test set with LinearRegression\n",
      "0.4164895901671564\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "clf = model.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print('Estimating RMSLE on the test set with LinearRegression')\n",
    "print(kaggle_score( y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating RMSLE on the test set with Lasso\n",
      "0.6736416145430251\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "model = Lasso(random_state=3)\n",
    "clf = model.fit(X_train, y_train)\n",
    "print('Estimating RMSLE on the test set with Lasso')\n",
    "print(kaggle_score( y_test, clf.predict(X_test) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating RMSLE on the test set with Lasso\n",
      "0.41649015670802203\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "model = Ridge(random_state=3)\n",
    "clf = model.fit(X_train, y_train)\n",
    "print('Estimating RMSLE on the test set with Lasso')\n",
    "print(kaggle_score( y_test, clf.predict(X_test) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating RMSLE on the test set with Lasso\n",
      "0.5824324330743528\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "model = ElasticNet(random_state=3, l1_ratio=0.0000001)\n",
    "clf = model.fit(X_train, y_train)\n",
    "print('Estimating RMSLE on the test set with Lasso')\n",
    "print(kaggle_score( y_test, clf.predict(X_test) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating RMSLE on the test set with Lasso\n",
      "0.46676467032269114\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model = DecisionTreeRegressor(random_state=3, max_depth=None, min_samples_split=2)\n",
    "clf = model.fit(X_train, y_train)\n",
    "print('Estimating RMSLE on the test set with Lasso')\n",
    "print(kaggle_score( y_test, clf.predict(X_test) ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luciano/Install/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating RMSLE on the test set with Lasso\n",
      "0.34154495163660903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.45528085083412867"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(random_state=3)\n",
    "clf = model.fit(X_train, y_train)\n",
    "print('Estimating RMSLE on the test set with Lasso')\n",
    "print(kaggle_score( y_test, clf.predict(X_test) ) )\n",
    "0.45528085083412867"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating RMSLE on the test set with Lasso\n",
      "0.3923103353785279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.40792254444974163"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "model = GradientBoostingRegressor(random_state=3)\n",
    "clf = model.fit(X_train, y_train)\n",
    "print('Estimating RMSLE on the test set with Lasso')\n",
    "print(kaggle_score( y_test, clf.predict(X_test) ) )\n",
    "0.40792254444974163"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating RMSLE on the test set with Lasso\n",
      "0.39225595593255225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4080742167350305"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "model = xgb.XGBRegressor(random_state=3)\n",
    "clf = model.fit(X_train, y_train)\n",
    "print('Estimating RMSLE on the test set with Lasso')\n",
    "print(kaggle_score( y_test, clf.predict(X_test) ) )\n",
    "0.4080742167350305"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   26.3s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   35.4s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   53.7s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.2min\n",
      "/home/luciano/Install/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  48 | elapsed:  1.6min remaining:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.1, 'solver': 'auto'}\n",
      "0.416490182506801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.41648924466344467"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# greater_is_better= False: we want to minimize the root mean square logarithmic error\n",
    "scorer = make_scorer(kaggle_score, greater_is_better= False)\n",
    "\n",
    "model = Ridge(random_state=3)\n",
    "\n",
    "parameters = {'alpha': [0.1, 5.0, 10.0, 50.0], 'solver': ['auto', 'lsqr', 'sag', 'svd']}\n",
    "# parameters = {'alpha': [0.1], 'solver': ['sag']}\n",
    "\n",
    "clf = GridSearchCV(model, param_grid= parameters, scoring= scorer, verbose= 10, n_jobs=-1, cv= 3)\n",
    "\n",
    "grid_fit = clf.fit(X_train, y_train)\n",
    "\n",
    "print(grid_fit.best_params_)\n",
    "best_clf_ridge = grid_fit.best_estimator_\n",
    "\n",
    "print(kaggle_score( y_test, best_clf_ridge.predict(X_test) ) )\n",
    "0.41648924466344467"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 16 candidates, totalling 32 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed: 29.4min\n",
      "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed: 38.3min\n",
      "[Parallel(n_jobs=6)]: Done  25 out of  32 | elapsed: 49.0min remaining: 13.7min\n",
      "[Parallel(n_jobs=6)]: Done  29 out of  32 | elapsed: 58.2min remaining:  6.0min\n",
      "[Parallel(n_jobs=6)]: Done  32 out of  32 | elapsed: 62.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 1.0, 'max_depth': 5, 'min_samples_split': 6, 'n_estimators': 200}\n",
      "0.3325317765694744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.35810574107314747"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "model = GradientBoostingRegressor(random_state=3)\n",
    "scorer = make_scorer(kaggle_score, greater_is_better= False)\n",
    "\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'max_depth': [3, 5],\n",
    "    'n_estimators': [100, 200],\n",
    "    'min_samples_split': [2, 6],\n",
    "    'learning_rate': [0.1, 1.0]\n",
    "}\n",
    "\n",
    "# parameters = {'learning_rate': [0.1], 'max_depth': [5], 'min_samples_split': [6], 'n_estimators': [200]}\n",
    "\n",
    "clf = GridSearchCV(model, param_grid= parameters, scoring= scorer, verbose= 10, cv= 2, n_jobs=6)\n",
    "\n",
    "grid_fit = clf.fit(X_train, y_train)\n",
    "\n",
    "print(grid_fit.best_params_)\n",
    "best_clf_gradient_boosting = grid_fit.best_estimator_\n",
    "\n",
    "print(kaggle_score( y_test, best_clf_gradient_boosting.predict(X_test) ) )\n",
    "0.35810574107314747"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 24 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed: 14.1min\n",
      "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed: 48.8min\n",
      "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed: 71.8min\n",
      "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed: 96.0min\n",
      "[Parallel(n_jobs=6)]: Done  42 out of  48 | elapsed: 129.9min remaining: 18.6min\n",
      "[Parallel(n_jobs=6)]: Done  48 out of  48 | elapsed: 150.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300, 'reg_lambda': 5}\n",
      "0.3140347959375159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.34973122433139087"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# greater_is_better= False: we want to minimize the root mean square logarithmic error\n",
    "scorer = make_scorer(kaggle_score, greater_is_better=False)\n",
    "\n",
    "model = xgb.XGBRegressor(random_state=3)\n",
    "\n",
    "parameters = {'max_depth': [5, 8, 10], 'n_estimators': [200, 300],\n",
    "              'learning_rate': [0.05, 0.1,], 'reg_lambda': [1.0, 5] }\n",
    "# parameters = {'learning_rate': [0.1], 'max_depth': [5], 'n_estimators': [300], 'reg_lambda': [5]}\n",
    "clf = GridSearchCV(model, param_grid= parameters, scoring= scorer, verbose= 10, cv=2, n_jobs=6)\n",
    "\n",
    "grid_fit = clf.fit(X_train, y_train)\n",
    "\n",
    "print(grid_fit.best_params_)\n",
    "best_clf_xgboost = grid_fit.best_estimator_\n",
    "\n",
    "print(kaggle_score( y_test, best_clf_xgboost.predict(X_test) ) )\n",
    "0.34973122433139087"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(PATH_TEST_DATASET, infer_datetime_format=True, parse_dates=['pickup_datetime'],  index_col='id')\n",
    "# df_test['pickup_datetime'] = df_test['pickup_datetime'].dt.to_pydatetime()\n",
    "df_test['pickup_date'] = df_test['pickup_datetime'].dt.date\n",
    "df_test['pickup_hour'] = df_test['pickup_datetime'].dt.hour\n",
    "df_test['pickup_weekday'] = df_test['pickup_datetime'].dt.day_name()\n",
    "\n",
    "holidays = [day.date() for day in calendar().holidays(start=df_test['pickup_date'].min(), end=df_test['pickup_date'].max())]\n",
    "df_test['holiday'] = df_test['pickup_date'].isin(holidays)\n",
    "df_test.drop('pickup_date', axis=1, inplace=True)\n",
    "df_test['distance'] = calculate_city_block_distance(df_test)\n",
    "df_test['distance'] = np.log(df_test['distance'] + 1)\n",
    "\n",
    "df_test = pd.get_dummies(df_test, columns=['vendor_id', 'passenger_count', \n",
    "                                    'store_and_fwd_flag', 'pickup_weekday', 'pickup_hour', 'holiday'])\n",
    "# df_test.drop(['pickup_datetime', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude'], axis=1, inplace=True)\n",
    "df_test.drop(['passenger_count_0', 'passenger_count_9'], axis=1, inplace=True)\n",
    "df_test.drop(['pickup_datetime'], axis=1, inplace=True)\n",
    "cols = ['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']\n",
    "df_test[cols] = df_test[cols].round(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/luciano/Personal/udacity/udacity_capstone_project/out/xgboost_latlong.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "BASE_PATH_KAGGLE_SUBMISISON = './out'\n",
    "\n",
    "def create_txt_file_for_submission(df_data, file_name):\n",
    "    \n",
    "    final_path = os.path.abspath(os.path.join(BASE_PATH_KAGGLE_SUBMISISON,file_name))\n",
    "    final_path += '.txt'\n",
    "    df_data.index.name = 'id'\n",
    "    print(final_path)\n",
    "    df_data.to_csv(final_path,\n",
    "                   sep=',',\n",
    "                   header=True,\n",
    "                   na_rep=df_data['trip_duration'].quantile(0.5)\n",
    "                  )\n",
    "    \n",
    "final_clf = sklearn.base.clone(best_clf_xgboost)\n",
    "final_clf.fit(df_X_train, df_y_train)\n",
    "model_name='xgboost_latlong'\n",
    "y_predict = final_clf.predict(df_test)\n",
    "y_predict = np.exp(y_predict) - 1\n",
    "df_result = pd.DataFrame(y_predict, columns=['trip_duration'], index=df_test.index.values)\n",
    "create_txt_file_for_submission(df_result, model_name)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final: 0.42976"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
