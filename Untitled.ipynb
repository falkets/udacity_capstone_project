{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the submission file\n",
    "\n",
    "The submission file must be formatted to be accepted by the automated submission scoring system. A sample of the final format is given with the datasets in the Challenge's page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "BASE_PATH_KAGGLE_SUBMISISON = './out'\n",
    "\n",
    "def create_txt_file_for_submission(df_data, file_name):\n",
    "    \n",
    "    final_path = os.path.abspath(os.path.join(BASE_PATH_KAGGLE_SUBMISISON,file_name))\n",
    "    final_path += '.txt'\n",
    "    df_data.index.name = 'id'\n",
    "    print(final_path)\n",
    "    df_data.to_csv(final_path,\n",
    "                   sep=',',\n",
    "                   header=True,\n",
    "                   na_rep=df_data['trip_duration'].quantile(0.5)\n",
    "                  )\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting the trip duration for the original test dataset\n",
    "\n",
    "As we stored the best models we'll now use an empty copy of them with the same parameters and train that again now with the whole original train dataset to get a better model for the final submission.\n",
    "\n",
    "After predicting the values for trip duration one submission file will be prepared for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model_specs in best_models.items():\n",
    "    clf = sklearn.base.clone(model_specs['clf'])\n",
    "    clf.fit(df_X_train, df_y_train)\n",
    "    y_predict = clf.predict(df_test)\n",
    "    y_predict = np.exp(y_predict) - 1\n",
    "    df_result = pd.DataFrame(y_predict, columns=['trip_duration'], index=df_test.index.values)\n",
    "    create_txt_file_for_submission(df_result, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The final results\n",
    "\n",
    "After submiting the prediction for each model, the final Scores are as follows:\n",
    "\n",
    "1. XGBoost: 0.49443\n",
    "1. Gradient Boost: 0.49671\n",
    "1. Ridge: 0.51110"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Achievements and Improvements\n",
    "\n",
    "Throughout the project, many topics related do data manipulation and visualization were covered, from opening the files, describing each of the columns, checking for null data, ploting the distributions, checking outliers, creating new features combining multiple columns, building simple models and evaluate them, fining tunning the best. \n",
    "\n",
    "The results achieved are coherent with the proposal, in which a score of 0.5 was the final goal.\n",
    "\n",
    "In the matter of improvements, the first step would be to play more with the hyperparameters to fine tunne them evn more, another point of improvement is to understand better in what areas the traffic is more intense by using clusterization for example, also is a good idea to add more sources of data like weather that have a big impact in trip duration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge Hyperparameters Tunnning\n",
    "\n",
    "The score for Ridge using the default parameters was 0.4283718167519953.\n",
    "\n",
    "The fine tunning tested the combination of the following parameters for the model using 3-fold cross-validation to evaluate the best result:\n",
    "\n",
    "* alpha: 0.5, 1.0, 3.0, 4.0, 5.0, 10.0\n",
    "* solver: *auto*, *least-squares* (lsqr), *Stochastic Average Gradient descent* (SAG), *Singular Value Decomposition* (SVD)\n",
    "\n",
    "The final parameter chosen was *alpha* = 5.0 and *solver* = *svd*, which had no practical improvement, with the score of 0.4283718279198734"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regressor Hyperparameters Tunnning\n",
    "\n",
    "The score for Gradient Boosting Regressor using the default parameters was 0.40940629859357985.\n",
    "\n",
    "The fine tunning tested the combination of the following parameters for the model using 2-fold cross-validation to evaluate the best result:\n",
    "\n",
    "* max_depth: 3, 5\n",
    "* n_estimators: 100, 200\n",
    "* min_samples_split: 2, 6\n",
    "* learning_rate : 0.1, 1.0\n",
    "\n",
    "The final parameters chosen was *learning_rate*: 0.1, *max_depth*: 5, *min_samples_split*: 6, *n_estimators*: 200, which improved the score to 0.39898042677040685"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Hyperparameters Tunnning\n",
    "\n",
    "The score for Gradient Boosting Regressor using the default parameters was 0.409344079071674.\n",
    "\n",
    "The fine tunning tested the combination of the following parameters for the model using 2-fold cross-validation to evaluate the best result:\n",
    "\n",
    "* max_depth: 5, 8, 10\n",
    "* n_estimators: 200, 300\n",
    "* learning_rate: 0.05, 0.1\n",
    "* reg_lambda: 1.0, 5\n",
    "\n",
    "The final parameters chosen was *learning_rate*: 0.1, *max_depth*: 5, *n_estimators*: 300, *reg_lambda*: 5, which improved the score to 0.39852413102654594"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import sklearn\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import xgboost as xgb\n",
    "import scipy\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "PATH_TRAIN_DATASET = './data/train.csv'\n",
    "PATH_TEST_DATASET = './data/test.csv'\n",
    "PATH_SAMPLE_SUMBISSION = './data/sample_submission.csv'\n",
    "\n",
    "NYC_DEGREE_KM = 111.05938787411571\n",
    "NYC_BOUNDING_BOX = [(40.4774,-74.2589), ( 40.9176, -73.7004)]\n",
    "\n",
    "def calculate_city_block_distance(df_data):\n",
    "    delta_lat = np.absolute(df_data.pickup_latitude - df_data.dropoff_latitude) * NYC_DEGREE_KM    \n",
    "    delta_lon = np.absolute(df_data.pickup_longitude - df_data.dropoff_longitude) * NYC_DEGREE_KM    \n",
    "    return delta_lat + delta_lon\n",
    "\n",
    "def kaggle_score(y_true_exp, y_pred_exp):\n",
    "    y_pred_exp = np.exp(y_pred_exp) - 1\n",
    "    y_true_exp = np.exp(y_true_exp) - 1\n",
    "    e_log_square = np.square( np.log(y_pred_exp + 1) - np.log(y_true_exp + 1))\n",
    "    score = np.sqrt((1/len(y_true_exp)) * np.sum(e_log_square))\n",
    "    return score\n",
    "\n",
    "df_test = pd.read_csv(PATH_TEST_DATASET, infer_datetime_format=True, parse_dates=['pickup_datetime'],  index_col='id')\n",
    "df_train = pd.read_csv(PATH_TRAIN_DATASET, infer_datetime_format=True,parse_dates=['pickup_datetime'], index_col='id')\n",
    "\n",
    "df_train.drop('dropoff_datetime', axis=1, inplace=True)\n",
    "df_train['pickup_datetime'] = df_train['pickup_datetime'].dt.to_pydatetime()\n",
    "df_test['pickup_datetime'] = df_test['pickup_datetime'].dt.to_pydatetime()\n",
    "\n",
    "Q1 = df_train['trip_duration'].quantile(0.25)\n",
    "Q3 = df_train['trip_duration'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "df_train = df_train[~((df_train['trip_duration'] < (Q1 - 1.5 * IQR)) |(df_train['trip_duration'] > (Q3 + 1.5 * IQR)))]\n",
    "\n",
    "df_train = df_train[df_train['trip_duration'] > 1]\n",
    "df_train = df_train[df_train['trip_duration'] < 7200]\n",
    "\n",
    "filter_lat_long = df_train['pickup_latitude'] < NYC_BOUNDING_BOX[1][0]\n",
    "filter_lat_long &= df_train['pickup_latitude'] > NYC_BOUNDING_BOX[0][0]\n",
    "filter_lat_long &= df_train['pickup_longitude'] < NYC_BOUNDING_BOX[1][1]\n",
    "filter_lat_long &= df_train['pickup_longitude'] > NYC_BOUNDING_BOX[0][1]\n",
    "\n",
    "filter_lat_long &= df_train['dropoff_latitude'] < NYC_BOUNDING_BOX[1][0]\n",
    "filter_lat_long &= df_train['dropoff_latitude'] > NYC_BOUNDING_BOX[0][0]\n",
    "filter_lat_long &= df_train['dropoff_longitude'] < NYC_BOUNDING_BOX[1][1]\n",
    "filter_lat_long &= df_train['dropoff_longitude'] > NYC_BOUNDING_BOX[0][1]\n",
    "\n",
    "\n",
    "df_train['distance'] = calculate_city_block_distance(df_train)\n",
    "df_train = df_train[df_train['distance'] > .1]\n",
    "df_train['avg_speed'] = df_train['distance']/(df_train['trip_duration']/3600)\n",
    "df_train = df_train[df_train['avg_speed'] < 100]\n",
    "df_train = df_train[df_train['avg_speed'] > 1]\n",
    "\n",
    "df_train.drop('avg_speed', axis=1, inplace=True)\n",
    "\n",
    "df_train['pickup_date'] = df_train['pickup_datetime'].dt.date\n",
    "df_train['pickup_hour'] = df_train['pickup_datetime'].dt.hour\n",
    "df_train['pickup_weekday'] = df_train['pickup_datetime'].dt.day_name()\n",
    "\n",
    "holidays = [day.date() for day in calendar().holidays(start=df_train['pickup_date'].min(),\n",
    "                                                      end=df_train['pickup_date'].max())]\n",
    "df_train['holiday'] = df_train['pickup_date'].isin(holidays)\n",
    "df_train.drop('pickup_date', axis=1, inplace=True)\n",
    "\n",
    "df_train = df_train[df_train['passenger_count']>0]\n",
    "\n",
    "cols = ['vendor_id', 'passenger_count','store_and_fwd_flag',\n",
    "        'pickup_weekday', 'pickup_hour', 'holiday']\n",
    "df_train = pd.get_dummies(df_train, columns=cols)\n",
    "\n",
    "cols = ['pickup_longitude', 'pickup_latitude', 'dropoff_longitude',\n",
    "        'dropoff_latitude', 'pickup_datetime', 'pickup_date']\n",
    "df_train.drop([cols], axis=1, inplace=True)\n",
    "# df_train[cols] = df_train[cols].round(3)\n",
    "\n",
    "df_train.drop('pickup_date', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "df_train['trip_duration'] = np.log(df_train['trip_duration'] + 1)\n",
    "df_train['distance'] = np.log(df_train['distance'] + 1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_y_train = df_train['trip_duration']\n",
    "df_X_train = df_train.drop(columns=['trip_duration'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X_train,\n",
    "                                                    df_y_train,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state = 3)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
